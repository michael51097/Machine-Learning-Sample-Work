{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final Project Part 1 - Autoencoder",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_Dn9rzyiqxi"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras import layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGLKx-6qiz-_"
      },
      "source": [
        "Upload the labels.csv and processed_counts.csv files to colab or your local workspace.\n",
        "\n",
        "This data associates a cell barcode, such as \"AAAGCCTGGCTAAC-1\", to a certain cell type label, such as \"CD14+ Monocyte\". For each cell barcode, there are also log RNA seq counts of 765 different genes, such as HES4.\n",
        "\n",
        "label.csv stores the association between a cell barcode and a cell type label.\n",
        "\n",
        "processed_counts.csv stores the normalized log read counts for each cell, where each row represents a single cell, and each column represents a gene."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WelsjSzviy4m"
      },
      "source": [
        "labels_pd = pd.read_csv(\"labels.csv\")\n",
        "counts_pd = pd.read_csv(\"processed_counts.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIX8kcTXi7EV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUxSCyz7jBQf"
      },
      "source": [
        "Shuffle your data. Make sure your labels and the counts are shuffled together.\n",
        "\n",
        "Split into train and test sets (80:20 split)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDTqBhcA7V8t"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHIg7i1k7U-G"
      },
      "source": [
        "Create a fully connected neural network for your autoencoder. Your latent space can be of any size less than or equal to 64. Too large may result in a poor visualization, and too small may result in high loss. 32 is a good starting point.\n",
        "\n",
        "Consider using more than 1 hidden layer, and a sparcity constraint (l1 regularization).\n",
        "\n",
        "Have an encoder model which is a model of only the layers for the encoding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8mvigLP7Sej"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gk1sfdNe76Kl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjQr4OYW76bN"
      },
      "source": [
        "Train your autoencoding using MSE loss.\n",
        "\n",
        "Finally, identify the parameters which don't overfit, and use the same model architecture and train on all of the data together.\n",
        "\n",
        "With a latent space size of 32, aim for 0.9 MSE loss on your test set, 0.95 with regularization. You will not be graded strictly on a loss cutoff."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4Q6KU3c8u-E"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Trjfxkk8wyg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yweQRGit8xDX"
      },
      "source": [
        "Use PCA and t-SNE on the dataset.\n",
        "\n",
        "Then use PCA on the latent space representation of the dataset.\n",
        "\n",
        "Plot all of these."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGa5B6Ir9KN4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2xcMPP09KxV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfOYsI9S9K5M"
      },
      "source": [
        "Compare the results of PCA, t-SNE, and your autoencoder as ways to visualize the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DPmGoHo9uwx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}